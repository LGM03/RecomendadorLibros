{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b82d11",
   "metadata": {},
   "source": [
    "## Nombres:\n",
    "- Juan Broto Ortega\n",
    "- Lidia González Martín"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e6ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, OWL\n",
    "import requests\n",
    "import sbc_tools as sbc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e5c8f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del endpoint de Wikidata\n",
    "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "class WikidataQuery:\n",
    "    def __init__(self):\n",
    "        self.sparql = SPARQLWrapper(WIKIDATA_ENDPOINT)\n",
    "        self.sparql.setReturnFormat(JSON)\n",
    "        \n",
    "        # User-Agent requerido por Wikidata\n",
    "        self.sparql.addCustomHttpHeader(\"User-Agent\", \n",
    "                                       \"SBC-Course/1.0 (educational-use)\")\n",
    "    \n",
    "    def execute_query(self, query):\n",
    "        \"\"\"Ejecutar consulta SPARQL con manejo de errores\"\"\"\n",
    "        try:\n",
    "            self.sparql.setQuery(query)\n",
    "            results = self.sparql.query().convert()\n",
    "            return results[\"results\"][\"bindings\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error en la consulta: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def results_to_dataframe(self, results):\n",
    "        \"\"\"Convertir resultados SPARQL a DataFrame de pandas\"\"\"\n",
    "        if not results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Extraer nombres de columnas\n",
    "        columns = results[0].keys()\n",
    "        \n",
    "        # Convertir a diccionario\n",
    "        data = []\n",
    "        for result in results:\n",
    "            row = {}\n",
    "            for col in columns:\n",
    "                if col in result:\n",
    "                    row[col] = result[col][\"value\"]\n",
    "                else:\n",
    "                    row[col] = None\n",
    "            data.append(row)\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "# Instanciar la clase\n",
    "wd = WikidataQuery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL_PROPIA = \"http://librosxxi.org/book/\"\n",
    "ONTO = Namespace(\"http://librosxxi.org/book-ontology/\") \n",
    "UMBRAL_JACCARD = 0.3\n",
    "class BookGenreOntology:\n",
    "    \"\"\"\n",
    "    Clase para construir una ontología RDF de géneros literarios narrativos desde Wikidata.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "        self.sparql.setReturnFormat(JSON)\n",
    "        self.graph = Graph()\n",
    "        \n",
    "        # Namespaces principales\n",
    "        self.WD = Namespace(\"http://www.wikidata.org/entity/\")\n",
    "        self.WDT = Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
    "        self.BOOK = Namespace(\"http://librosxxi.org/book-genre/\")\n",
    "\n",
    "        # Vocabs externos\n",
    "        self.DC = Namespace(\"http://purl.org/dc/elements/1.1/\")\n",
    "        self.BIBO = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "        self.SCHEMA = Namespace(\"http://schema.org/\")\n",
    "        self.FOAF = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "        self.ONTO = ONTO\n",
    "\n",
    "        # Bind al grafo\n",
    "        self.graph.bind(\"wd\", self.WD)\n",
    "        self.graph.bind(\"wdt\", self.WDT)\n",
    "        self.graph.bind(\"book\", self.BOOK)\n",
    "\n",
    "        self.graph.bind(\"dc\", self.DC)\n",
    "        self.graph.bind(\"bibo\", self.BIBO)\n",
    "        self.graph.bind(\"schema\", self.SCHEMA)\n",
    "        self.graph.bind(\"foaf\", self.FOAF)\n",
    "        self.graph.bind(\"onto\", self.ONTO)\n",
    "        \n",
    "        self.graph.bind(\"owl\", OWL)\n",
    "        self.graph.bind(\"rdfs\", RDFS)\n",
    "\n",
    "\n",
    "    def execute_query(self, query):\n",
    "        \"\"\"Ejecuta una consulta SPARQL en Wikidata\"\"\"\n",
    "        time.sleep(7)  # Respetar límites\n",
    "        try:\n",
    "            self.sparql.setQuery(query)\n",
    "            results = self.sparql.query().convert()\n",
    "            return results[\"results\"][\"bindings\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error ejecutando consulta: {e}\")\n",
    "            return []\n",
    "    \n",
    "\n",
    "    def build_genre_taxonomy_from_wikidata(self, max_depth: int = None) -> Graph:\n",
    "        \"\"\"\n",
    "        Consulta Wikidata y construye una ontología RDF con la jerarquía de géneros narrativos.\n",
    "        \"\"\"\n",
    "        \n",
    "        if max_depth is None:\n",
    "            depth_path = \"wdt:P279*\"\n",
    "        else:\n",
    "            depth_path = \"wdt:P279\"\n",
    "            for i in range(1, max_depth):\n",
    "                depth_path += \"/wdt:P279?\"\n",
    "\n",
    "        query = f\"\"\"\n",
    "        SELECT DISTINCT ?genre ?genreLabel ?parent ?parentLabel WHERE {{\n",
    "          \n",
    "          ?genre {depth_path} wd:Q1318295 .\n",
    "          \n",
    "          ?genre wdt:P279 ?parent .\n",
    "          ?parent wdt:P279* wd:Q1318295 .\n",
    "          \n",
    "          ?genre rdfs:label ?genreLabel .\n",
    "          FILTER (LANG(?genreLabel) = 'en')\n",
    "          \n",
    "          ?parent rdfs:label ?parentLabel .\n",
    "          FILTER (LANG(?parentLabel) = 'en')\n",
    "        }}\n",
    "        ORDER BY ?genreLabel\n",
    "        \"\"\"\n",
    "\n",
    "        bindings = self.execute_query(query)\n",
    "\n",
    "        if bindings:\n",
    "            self._build_rdf_graph(bindings)\n",
    "        \n",
    "        return self.graph\n",
    "    \n",
    "\n",
    "    def _build_rdf_graph(self, bindings: list) -> None:\n",
    "        print(f\"\\nProcesando {len(bindings)} resultados...\")\n",
    "        \n",
    "        # Añadir definición de la clase raíz\n",
    "        self.graph.add((self.ONTO[\"LibrosXXI\"], RDF.type, OWL.Class))\n",
    "        self.graph.add((self.ONTO[\"LibrosXXI\"], RDFS.label, Literal(\"Libros siglo XXI\")))\n",
    "        self.graph.add((self.ONTO[\"LibrosXXI\"], RDFS.subClassOf, self.WD[\"Q571\"])) #Hereda de libro de wikidata \n",
    "        self.graph.add((self.ONTO[\"LibrosXXI\"], OWL.equivalentClass, self.DC.BibliographicResource)) ##Equivalente a recurso bibliográfico de Dublin Core\n",
    "        self.graph.add((self.ONTO[\"LibrosXXI\"], OWL.equivalentClass, self.SCHEMA.Book)) \n",
    "        self.graph.add((self.ONTO[\"LibrosXXI\"], OWL.equivalentClass, self.BIBO.Book))\n",
    "        # Agregamos las propiedades y entidades que correponden a los libros \n",
    "        # ------------------ año ------------------\n",
    "        self.graph.add((self.ONTO.año, RDF.type, OWL.DatatypeProperty)) #Incluimos el año como una propiedad\n",
    "        self.graph.add((self.ONTO.año, RDFS.label, Literal(\"Año de publicación\")))\n",
    "        self.graph.add((self.ONTO.año, OWL.equivalentProperty, self.DC.date)) ## Equivalente a fecha de dublin core\n",
    "        self.graph.add((self.ONTO.año, OWL.equivalentProperty, self.BIBO.created)) ##Equivalente a creado de bibo\n",
    "        self.graph.add((self.ONTO.año, OWL.equivalentProperty, self.SCHEMA.datePublished)) ##equivalente a la fecha de publicación de schema.org\n",
    "\n",
    "        # ------------------ ISBN ------------------\n",
    "        self.graph.add((self.ONTO.isbn, RDF.type, OWL.DatatypeProperty))\n",
    "        self.graph.add((self.ONTO.isbn, RDFS.label, Literal(\"ISBN\")))\n",
    "        self.graph.add((self.ONTO.isbn, OWL.equivalentProperty, self.SCHEMA.isbn)) ##Equivalente a isbn de schema.org\n",
    "        self.graph.add((self.ONTO.isbn, OWL.equivalentProperty, self.BIBO.isbn))  ##equivalente a isbn de bibo\n",
    "\n",
    "        # ------------------ Género ------------------\n",
    "        self.graph.add((self.ONTO.Genero, RDF.type, OWL.Class))  ##Creamos una clase para género\n",
    "        self.graph.add((self.ONTO.Genero, RDFS.label, Literal('Genero')))  ##Damos un Label al género\n",
    "        self.graph.add((self.ONTO.Genero, RDFS.subClassOf, self.WDT['Q1792379'])) ##Hereda de la clase de wikidata de genero artístico\n",
    "        self.graph.add((self.ONTO.Genero, OWL.equivalentClass, self.SCHEMA.Genre)) #Equivalente a genero de schema\n",
    "        self.graph.add((self.ONTO.Genero, OWL.equivalentClass, self.BIBO.DocumentPart)) ##Equivalente a document part de bibo\n",
    "\n",
    "        self.graph.add((self.ONTO.tieneGenero, RDF.type, OWL.ObjectProperty)) \n",
    "        self.graph.add((self.ONTO.tieneGenero, RDFS.domain, self.ONTO[\"LibrosXXI\"])) #Dentro del dominio de libros\n",
    "        self.graph.add((self.ONTO.tieneGenero, RDFS.range, self.ONTO.Genero)) ## En el rango de genero\n",
    "        self.graph.add((self.ONTO.tieneGenero, OWL.equivalentProperty, self.SCHEMA.genre)) #equivalente a la propiedad genero\n",
    "        self.graph.add((self.ONTO.tieneGenero, OWL.equivalentProperty, self.DC.subject)) ## Equivalente a la propiedad tema de dc\n",
    "\n",
    "        # ------------------ Autor ------------------\n",
    "        self.graph.add((self.ONTO.Autor, RDF.type, OWL.Class))  ##Creamos una clase autor\n",
    "        self.graph.add((self.ONTO.Autor, RDFS.label, Literal('Autor')))  ##Damos un Label al autor\n",
    "        self.graph.add((self.ONTO.Autor, RDFS.subClassOf, self.WDT['Q5'])) ##Hereda de la clase de wikidata de humano\n",
    "        self.graph.add((self.ONTO.Autor, OWL.equivalentClass, self.BIBO.Person))\n",
    "        self.graph.add((self.ONTO.Autor, OWL.equivalentClass, self.SCHEMA.Person))\n",
    "        self.graph.add((self.ONTO.Autor, OWL.equivalentClass, self.FOAF.Person))\n",
    "\n",
    "        self.graph.add((self.ONTO.tieneAutor, RDF.type, OWL.ObjectProperty))\n",
    "        self.graph.add((self.ONTO.tieneAutor, RDFS.domain, self.ONTO[\"LibrosXXI\"]))\n",
    "        self.graph.add((self.ONTO.tieneAutor, RDFS.range, self.ONTO.Autor))\n",
    "        self.graph.add((self.ONTO.tieneAutor, OWL.equivalentProperty,self.SCHEMA.author))\n",
    "        self.graph.add((self.ONTO.tieneAutor, OWL.equivalentProperty,self.DC.creator))\n",
    "        self.graph.add((self.ONTO.tieneAutor, OWL.equivalentProperty,self.BIBO.authorList))\n",
    "\n",
    "        # ------------------ Editorial ------------------\n",
    "        self.graph.add((self.ONTO.Editorial, RDF.type, OWL.Class))  # Clase para Editorial\n",
    "        self.graph.add((self.ONTO.Editorial, RDFS.label, Literal(\"Editorial\")))\n",
    "        self.graph.add((self.ONTO.Editorial, OWL.equivalentClass, self.SCHEMA.Publisher))  # Equivalente a publisher de schema\n",
    "        self.graph.add((self.ONTO.Editorial, OWL.equivalentClass, self.BIBO.Publisher))    # Equivalente a publisher de bibo\n",
    "\n",
    "        self.graph.add((self.ONTO.tieneEditorial, RDF.type, OWL.ObjectProperty))\n",
    "        self.graph.add((self.ONTO.tieneEditorial, RDFS.domain, self.ONTO[\"LibrosXXI\"]))\n",
    "        self.graph.add((self.ONTO.tieneEditorial, RDFS.range, self.ONTO.Editorial))\n",
    "        self.graph.add((self.ONTO.tieneEditorial, OWL.equivalentProperty, self.SCHEMA.publisher))\n",
    "        self.graph.add((self.ONTO.tieneEditorial, OWL.equivalentProperty, self.DC.publisher))\n",
    "        self.graph.add((self.ONTO.tieneEditorial, OWL.equivalentProperty, self.BIBO.publisher))\n",
    "\n",
    "\n",
    "        # ------------------ Tiene formato ebook ------------------\n",
    "        self.graph.add((self.ONTO.epubAccesibility, RDF.type, OWL.DatatypeProperty))  # Propiedad tipo literal (boolean o string)\n",
    "        self.graph.add((self.ONTO.epubAccesibility, RDFS.label, Literal(\"Tiene formato ebook\")))\n",
    "        self.graph.add((self.ONTO.epubAccesibility, OWL.equivalentProperty, self.SCHEMA.bookFormat))\n",
    "\n",
    "\n",
    "        # ------------------ Descripcion ------------------\n",
    "        self.graph.add((self.ONTO.descripcion, RDF.type, OWL.DatatypeProperty))  # Propiedad de texto\n",
    "        self.graph.add((self.ONTO.descripcion, RDFS.label, Literal(\"Descripción\")))\n",
    "        self.graph.add((self.ONTO.descripcion, OWL.equivalentProperty, self.SCHEMA.description))\n",
    "        self.graph.add((self.ONTO.descripcion, OWL.equivalentProperty, self.DC.description))\n",
    "\n",
    "\n",
    "        # ------------------ Maturity rating ------------------\n",
    "        self.graph.add((self.ONTO.maturityRating, RDF.type, OWL.DatatypeProperty))  # Propiedad tipo literal\n",
    "        self.graph.add((self.ONTO.maturityRating, RDFS.label, Literal(\"Maturity Rating\")))\n",
    "        self.graph.add((self.ONTO.maturityRating, OWL.equivalentProperty, self.SCHEMA.contentRating))\n",
    "\n",
    "\n",
    "        # ------------------ Usuarios ------------------\n",
    "        self.graph.add((self.ONTO.Usuario, RDF.type, OWL.Class))  # Clase para Usuario\n",
    "        self.graph.add((self.ONTO.Usuario, RDFS.label, Literal(\"Usuario\")))\n",
    "        self.graph.add((self.ONTO.Usuario, OWL.equivalentClass, self.SCHEMA.Person))  # Equivalente a Person de schema\n",
    "\n",
    "        self.graph.add((self.ONTO.edad, RDF.type, OWL.ObjectProperty)) \n",
    "        self.graph.add((self.ONTO.edad, RDFS.label, Literal(\"Edad\")))\n",
    "        self.graph.add((self.ONTO.edad, OWL.equivalentProperty, self.SCHEMA.age))\n",
    "\n",
    "        self.graph.add((self.ONTO.leGusta, RDF.type, OWL.ObjectProperty)) # Propiedad para relacionar usuario y libro\n",
    "        self.graph.add((self.ONTO.leGusta, RDFS.domain, self.ONTO.Usuario)) # Dentro del dominio de usuario\n",
    "        self.graph.add((self.ONTO.leGusta, RDFS.range, self.ONTO[\"LibrosXXI\"])) # En el rango de libros\n",
    "\n",
    "\n",
    "\n",
    "        # Conjuntos para tracking\n",
    "        self.genres_added = {}\n",
    "        \n",
    "        # Procesar cada resultado\n",
    "        for i, binding in enumerate(bindings):\n",
    "            # Extraer información del género\n",
    "            genre_uri = URIRef(binding['genre']['value'])\n",
    "            genre_label = binding['genreLabel']['value']\n",
    "            # Extraer información del padre\n",
    "            parent_uri = URIRef(binding['parent']['value'])\n",
    "            parent_label = binding.get('parentLabel', {}).get('value', '')\n",
    "            \n",
    "            # Añadir el género como una clase OWL\n",
    "            if genre_uri not in self.genres_added:\n",
    "\n",
    "                self.graph.add((genre_uri, RDF.type, self.ONTO.Genero))\n",
    "\n",
    "                self.graph.add((genre_uri, RDFS.label, Literal(genre_label, lang=\"en\")))\n",
    "                self.genres_added[genre_uri]=genre_label\n",
    "            \n",
    "            # Añadir el padre como una clase OWL\n",
    "            if parent_uri not in self.genres_added:\n",
    "                \n",
    "                self.graph.add((parent_uri, RDF.type, self.ONTO.Genero))\n",
    "\n",
    "                if parent_label:\n",
    "                    self.graph.add((parent_uri, RDFS.label, Literal(parent_label, lang=\"en\")))\n",
    "                self.genres_added[parent_uri]=parent_label\n",
    "        \n",
    "            self.graph.add((genre_uri, RDFS.subClassOf, parent_uri))\n",
    "            \n",
    "        print(f\"Procesamiento completado\")\n",
    "\n",
    "    #Funcion de búsqueda de libros en Google Books\n",
    "    def get_google_instances(self, genre_label: str, n: int = 5) -> list:\n",
    "        \n",
    "        url = f\"https://www.googleapis.com/books/v1/volumes?q=subject:{genre_label.replace(' ', '+')}&maxResults={n}\"\n",
    "\n",
    "        resp = requests.get(url)\n",
    "        data = resp.json()\n",
    "        sol= []\n",
    "        try:\n",
    "            if 'items' in data:\n",
    "                books = data['items']\n",
    "                for book in books:\n",
    "                    res= {}\n",
    "                    if 'volumeInfo' in book:\n",
    "\n",
    "                        if 'title' in book['volumeInfo']:\n",
    "                            res['titulo']=book['volumeInfo']['title']\n",
    "\n",
    "                        if 'authors' in book['volumeInfo']:\n",
    "                            autores = []\n",
    "                            for author in book['volumeInfo']['authors']:\n",
    "                                autores.append((URIRef(f\"{URL_PROPIA}_author={author.replace(' ', '_')}\"), author))\n",
    "                            res['autores']=autores\n",
    "                        \n",
    "                        if 'publisher' in book['volumeInfo']:\n",
    "                            editorial =book['volumeInfo']['publisher']\n",
    "                            res['editorial'] = (URIRef(f\"{URL_PROPIA}_editorial={editorial.replace(' ', '_')}\"), editorial)\n",
    "                        \n",
    "                        if 'publishedDate' in book['volumeInfo']:\n",
    "                            res['año']=book['volumeInfo']['publishedDate']\n",
    "\n",
    "                        if 'description' in book['volumeInfo']:\n",
    "                            res['description']=book['volumeInfo']['description']\n",
    "\n",
    "                        if 'industryIdentifiers' in book['volumeInfo']:\n",
    "                            identifier = book['volumeInfo']['industryIdentifiers'][0] ##Me quedo con el primer ISBN que haya \n",
    "                            res['isbn']=identifier['identifier']\n",
    "\n",
    "                        if 'maturityRating' in book['volumeInfo']:\n",
    "                            res['maturityRating']=book['volumeInfo']['maturityRating']  \n",
    "                    if 'epub' in book['accessInfo']:\n",
    "                        res['epubAccessibility']=book['accessInfo']['epub']['isAvailable']\n",
    "\n",
    "                    sol.append(res)\n",
    "\n",
    "                    \n",
    "        except Exception as e:\n",
    "            return None\n",
    "                \n",
    "        #Devolvemos un lista de diccionarios con la información de los libros\n",
    "        return sol\n",
    "\n",
    "    #Función de búsqueda de libros en Wikidata\n",
    "    def get_wikidata_book_instances(self, genre_uri: str, n: int = 5) -> list:\n",
    "        genero = genre_uri.split('/')[-1] ##Buscamos por la Q del género\n",
    "        rm_query = f\"\"\"\n",
    "        PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "        PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX schema: <http://schema.org/>\n",
    "\n",
    "        SELECT DISTINCT \n",
    "          ?libros \n",
    "          ?titulo \n",
    "          ?año \n",
    "          ?editorial \n",
    "          ?es_ebook \n",
    "          ?descripcion \n",
    "          ?clasificacion_edad \n",
    "          ?isbn\n",
    "          (GROUP_CONCAT(DISTINCT ?autorNombre; separator=\";\") AS ?autores)\n",
    "        WHERE {{\n",
    "            ?libros wdt:P31 wd:Q7725634 ;\n",
    "                    wdt:P136 wd:{genero} ; # Parámetro de género\n",
    "                    rdfs:label ?titulo .\n",
    "            FILTER (lang(?titulo) = \"en\")\n",
    "\n",
    "            OPTIONAL {{ \n",
    "                ?libros schema:description ?descripcion .\n",
    "                FILTER (lang(?descripcion) = \"en\")\n",
    "            }}\n",
    "\n",
    "            OPTIONAL {{ \n",
    "                ?libros wdt:P50 ?autorEntity .\n",
    "                ?autorEntity rdfs:label ?autorNombre .\n",
    "                FILTER (lang(?autorNombre) = \"en\") \n",
    "            }}\n",
    "\n",
    "            OPTIONAL {{\n",
    "                ?libros wdt:P123 ?editorialEntity .\n",
    "                ?editorialEntity rdfs:label ?editorial .\n",
    "                FILTER (lang(?editorial) = \"en\")\n",
    "            }}\n",
    "\n",
    "            BIND(IF(EXISTS {{ ?libros wdt:P437 wd:Q3331189 }}, \"Yes\", \"No\") AS ?es_ebook)\n",
    "\n",
    "            OPTIONAL {{\n",
    "                ?libros wdt:P2360 ?targetAudience .\n",
    "                ?targetAudience rdfs:label ?clasificacion_edad .\n",
    "                FILTER (lang(?clasificacion_edad) = \"en\")\n",
    "            }}\n",
    "\n",
    "            OPTIONAL {{ \n",
    "                ?libros wdt:P577 ?fecha .\n",
    "                BIND(YEAR(?fecha) AS ?año) \n",
    "            }}\n",
    "\n",
    "            OPTIONAL {{ ?libros wdt:P212 ?isbn . }}\n",
    "        }}\n",
    "        GROUP BY ?libros ?titulo ?año ?editorial ?es_ebook ?descripcion ?clasificacion_edad ?isbn\n",
    "        ORDER BY DESC(?año)\n",
    "        LIMIT {n}\n",
    "        \"\"\"\n",
    "\n",
    "        wd = WikidataQuery()\n",
    "        rm_results = wd.execute_query(rm_query)\n",
    "\n",
    "        libro = {}\n",
    "        sol = []\n",
    "        for entity in rm_results:\n",
    "                if 'titulo' in entity:\n",
    "                    libro['titulo']=entity[\"titulo\"][\"value\"]  \n",
    "                if 'autores' in entity:\n",
    "                    autores = entity[\"autores\"][\"value\"].split(\";\")\n",
    "                    autores_list = []\n",
    "                    for author in autores:\n",
    "                        autores_list.append((URIRef(f\"{URL_PROPIA}_author={author.replace(' ', '_').replace(':', '').replace(',', '').replace('(', '').replace(')', '').replace('.', '').replace('\"', '').lower()}\"), author))\n",
    "                    libro['autores']=autores_list   \n",
    "\n",
    "                if 'editorial' in entity:                     \n",
    "                    editorial =entity[\"editorial\"][\"value\"]\n",
    "                    libro['editorial'] = (URIRef(f\"{URL_PROPIA}_editorial={editorial.replace(' ', '_').replace(':', '').replace(',', '').replace('(', '').replace(')', '').replace('.', '').replace('\"', '').lower()}\"), editorial)\n",
    "                \n",
    "                if 'año' in entity:\n",
    "                    libro['año']=entity[\"año\"][\"value\"]\n",
    "\n",
    "                if 'descripcion' in entity:\n",
    "                    libro['description']=entity[\"descripcion\"][\"value\"]\n",
    "\n",
    "                if 'isbn' in entity:\n",
    "                    libro['isbn']=entity[\"isbn\"][\"value\"]\n",
    "                if 'clasificacion_edad' in entity:\n",
    "                    libro['maturityRating']=entity[\"clasificacion_edad\"][\"value\"]  \n",
    "                if 'libro' in entity:\n",
    "                    libro['epubAccessibility']=entity[\"es_ebook\"][\"value\"]\n",
    "                sol.append(libro)\n",
    "\n",
    "        return sol #Retornamos la lista de diccionarios con la información de los libros\n",
    "\n",
    "    #Función de búsqueda de libros en OpenLibrary\n",
    "    def get_openLibrary_book_instances(self,genero: str, n: int = 5) -> list:\n",
    "        # 1. Búsqueda por género\n",
    "        search_url = f\"https://openlibrary.org/subjects/{genero.lower().replace(' ', '_')}.json?limit={n}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(search_url)\n",
    "            data = response.json()\n",
    "            obras = data.get('works', [])\n",
    "        except Exception as e:\n",
    "            return []\n",
    "\n",
    "        resultados = []\n",
    "\n",
    "        for obra in obras:\n",
    "            libro = {}\n",
    "            \n",
    "            if obra.get('title'):\n",
    "                libro[\"titulo\"] = obra.get('title')\n",
    "            \n",
    "            autores_list = []\n",
    "            for author in libro.get('autores', []):\n",
    "                autores_list.append((URIRef(f\"{URL_PROPIA}_author={author.replace(' ', '_').replace(':', '').replace(',', '').replace('(', '').replace(')', '').replace('.', '').replace('\"', '').lower()}\"), author))\n",
    "            libro['autores']=autores_list\n",
    "            \n",
    "            work_key = obra.get('key')\n",
    "            edition_key = obra.get('cover_edition_key') or (obra.get('editions')[0].get('key') if obra.get('editions') else None)\n",
    "\n",
    "            # 2. Detalles de la Obra (Descripción y Edad)\n",
    "            detalles_obra = requests.get(f\"https://openlibrary.org{work_key}.json\").json()\n",
    "            \n",
    "            # 3. Detalles de la Edición (Editorial, ISBN, Fecha)\n",
    "            detalles_edicion = {}\n",
    "            if edition_key:\n",
    "                path = edition_key if edition_key.startswith('/') else f\"/books/{edition_key}\"\n",
    "                detalles_edicion = requests.get(f\"https://openlibrary.org{path}.json\").json()\n",
    "\n",
    "            # Fecha de publicación / Año\n",
    "            anio = detalles_edicion.get('publish_date') or obra.get('first_publish_year')\n",
    "            if anio:\n",
    "                libro[\"año\"] = anio\n",
    "\n",
    "            # Editorial\n",
    "            pubs = detalles_edicion.get('publishers')\n",
    "            if pubs and pubs[0]:\n",
    "                libro[\"editorial\"] = ((URIRef(f\"{URL_PROPIA}_editorial={pubs[0].replace(' ', '_').replace(':', '').replace(',', '').replace('(', '').replace(')', '').replace('.', '').replace('\"', '').lower()}\"), pubs[0]))\n",
    "            # ISBN (Primero que encuentre)\n",
    "            isbns = detalles_edicion.get('isbn_13') or detalles_edicion.get('isbn_10')\n",
    "            if isbns and isbns[0]:\n",
    "                libro[\"isbn\"] = isbns[0]\n",
    "\n",
    "            # Accesibilidad Ebook\n",
    "            if obra.get('has_fulltext'):\n",
    "                libro[\"epubAccessibility\"] = \"Disponible (ePub/PDF)\"\n",
    "\n",
    "            # Clasificación (Solo si se detecta un rango específico)\n",
    "            subjects = [s.lower() for s in obra.get('subject', [])]\n",
    "            if any(x in subjects for x in ['erotica', 'explicit', 'adult content']):\n",
    "                libro[\"clasificacion\"] = \"+18\"\n",
    "            elif any(x in subjects for x in ['juvenile', 'children', 'infantil']):\n",
    "                libro[\"clasificacion\"] = \"0-12 años\"\n",
    "            elif \"young adult\" in subjects:\n",
    "                libro[\"clasificacion\"] = \"13-17 años (Juvenil)\"\n",
    "\n",
    "            # Descripción\n",
    "            desc_data = detalles_obra.get('description')\n",
    "            if desc_data:\n",
    "                descripcion = desc_data.get('value') if isinstance(desc_data, dict) else desc_data\n",
    "                if descripcion:\n",
    "                    libro[\"descripcion\"] = descripcion[:400] + \"...\"\n",
    "\n",
    "            resultados.append(libro)\n",
    "\n",
    "        return resultados\n",
    "\n",
    "    #Función de búsqueda de libros en DBpedia\n",
    "    def get_dbpedia_book_instances(self, wikidata_genre_uri: str, n: int = 5) -> list:\n",
    "        url = \"https://dbpedia.org/sparql\"\n",
    "        wikidata_id = wikidata_genre_uri.split('/')[-1]\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "\n",
    "        SELECT DISTINCT ?book ?title ?desc ?year ?publisher ?isbn (GROUP_CONCAT(DISTINCT ?authorName; separator=\", \") AS ?authors)\n",
    "        WHERE {{\n",
    "            # Relación entre Wikidata y DBpedia\n",
    "            {{ ?genre owl:sameAs <http://www.wikidata.org/entity/{wikidata_id}> . }}\n",
    "            UNION\n",
    "            {{ ?genre owl:sameAs <https://www.wikidata.org/entity/{wikidata_id}> . }}\n",
    "            \n",
    "            # Asociación de libro a género\n",
    "            {{ ?book dbo:genre ?genre . }} UNION {{ ?book dbo:literaryGenre ?genre . }}\n",
    "            \n",
    "            ?book a dbo:Book ;\n",
    "                rdfs:label ?title .\n",
    "            FILTER(lang(?title) = \"en\")\n",
    "\n",
    "            OPTIONAL {{ \n",
    "                ?book dbo:author ?author . \n",
    "                ?author rdfs:label ?authorName . \n",
    "                FILTER(lang(?authorName) = \"en\") \n",
    "            }}\n",
    "            OPTIONAL {{ ?book dbo:abstract ?desc . FILTER(lang(?desc) = \"en\") }}\n",
    "            OPTIONAL {{ ?book dbo:releaseDate ?date . BIND(year(xsd:date(?date)) AS ?year) }}\n",
    "            OPTIONAL {{ ?book dbo:publisher ?pub . ?pub rdfs:label ?publisher . FILTER(lang(?publisher) = \"en\") }}\n",
    "            OPTIONAL {{ ?book dbo:isbn ?isbn . }}\n",
    "        }}\n",
    "        GROUP BY ?book ?title ?desc ?year ?publisher ?isbn\n",
    "        LIMIT {n}\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = requests.get(url, params={'query': query, 'format': 'json'}, timeout=15)\n",
    "            bindings = response.json().get('results', {}).get('bindings', [])\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "        resultados = []\n",
    "        for b in bindings:\n",
    "            libro = {}\n",
    "            \n",
    "            # Solo añadimos al diccionario si el campo existe en la respuesta de la API\n",
    "            if 'title' in b:\n",
    "                libro[\"titulo\"] = b['title']['value']\n",
    "            \n",
    "            if 'authors' in b and b['authors']['value'] != \"\":\n",
    "                autores = b['authors']['value'].split(\", \")\n",
    "                autores_list = []\n",
    "                for author in autores:\n",
    "                    autores_list.append((URIRef(f\"{URL_PROPIA}_author={author.replace(' ', '_').replace(':', '').replace(',', '').replace('(', '').replace(')', '').replace('.', '').replace('\"', '').lower()}\"), author))\n",
    "                libro['autores']=autores_list   \n",
    "\n",
    "                \n",
    "            if 'year' in b:\n",
    "                libro[\"año\"] = b['year']['value']\n",
    "                \n",
    "            if 'publisher' in b:\n",
    "                libro[\"editorial\"] = ((URIRef(f\"{URL_PROPIA}_editorial={b['publisher']['value'].replace(' ', '_').replace(':', '').replace(',', '').replace('(', '').replace(')', '').replace('.', '').replace('\"', '').lower()}\"), b['publisher']['value']))\n",
    "                \n",
    "            if 'isbn' in b:\n",
    "                libro[\"isbn\"] = b['isbn']['value']\n",
    "                \n",
    "            if 'desc' in b:\n",
    "                abstract = b['desc']['value']\n",
    "                libro[\"descripcion\"] = abstract[:400] + \"...\"\n",
    "                \n",
    "                # Clasificación basada en el abstract (si existe)\n",
    "                lower_abs = abstract.lower()\n",
    "                if any(x in lower_abs for x in [\"erotica\", \"explicit\"]):\n",
    "                    libro[\"clasificacion\"] = \"+18\"\n",
    "                elif any(x in lower_abs for x in [\"children's\", \"juvenile\"]):\n",
    "                    libro[\"clasificacion\"] = \"0-12 años\"\n",
    "                elif \"young adult\" in lower_abs:\n",
    "                    libro[\"clasificacion\"] = \"13-17 años\"\n",
    "            \n",
    "            resultados.append(libro)\n",
    "\n",
    "        return resultados #Retornamos la lista de diccionarios con la información de los libros\n",
    "\n",
    "    #Función para añadir las instancias de libros a la ontología\n",
    "    def add_instances_to_ontology(self, n_per_genre: int = 50) -> None:\n",
    "        total_books = 0\n",
    "        for genre_uri, genre_label in self.genres_added.items():\n",
    "            try:\n",
    "                ##Función de búsqueda de libros en Google Books API\n",
    "                book_instances = self.get_google_instances(genre_label, n_per_genre)\n",
    "                ##Función de búsqueda de libros en Wikidata\n",
    "                book_instances_wikidata = self.get_wikidata_book_instances(genre_uri, n_per_genre)\n",
    "                ##Función de búsqueda de libros en DBpedia\n",
    "                book_instances_dbpedia = self.get_dbpedia_book_instances(genre_uri, n_per_genre)\n",
    "\n",
    "                if book_instances:\n",
    "                    total_books += self._add_books_to_graph(book_instances, genre_uri)\n",
    "                if book_instances_wikidata:\n",
    "                    total_books += self._add_books_to_graph(book_instances_wikidata, genre_uri)\n",
    "                if book_instances_dbpedia:\n",
    "                    total_books += self._add_books_to_graph(book_instances_dbpedia, genre_uri)\n",
    "                print(total_books)\n",
    "            except Exception as e:\n",
    "                pass #En caso de error seguimos con el siguiente género\n",
    "        print(f\"Total libros añadidos: {total_books}\")\n",
    "\n",
    "    #Función interna para añadir libros al grafo RDF\n",
    "    def _add_books_to_graph(self, rm_results: dict, genre_uri: URIRef) -> int:\n",
    "    \n",
    "        count = 0\n",
    "        for entity in rm_results:\n",
    "            # URI y label del libro (obligatorio)\n",
    "            entity_uri =  URIRef(f\"{URL_PROPIA}_titulo={entity[\"titulo\"].replace(' ', '_').replace(':', '').replace(',', '').replace('(', '').replace(')', '').replace('.', '').replace('\"', '').lower()}\")\n",
    "            if (entity_uri, RDF.type, self.ONTO[\"LibrosXXI\"]) in self.graph:\n",
    "                continue  # Ya existe no lo metemos otra vez\n",
    "            entity_label = entity[\"titulo\"]\n",
    "            \n",
    "            self.graph.add((entity_uri, RDF.type, self.ONTO[\"LibrosXXI\"])) #Tipo libro siglo XXI\n",
    "\n",
    "            self.graph.add((entity_uri, RDFS.label, Literal(entity_label))) #Label del libro\n",
    "\n",
    "            self.graph.add((entity_uri, self.ONTO.tieneGenero, genre_uri)) #Relación con el género\n",
    "\n",
    "  \n",
    "            if 'año' in entity: \n",
    "                self.graph.add((entity_uri, self.ONTO.año, Literal(entity['año'])))\n",
    "\n",
    "            if 'isbn' in entity:\n",
    "                self.graph.add((entity_uri, self.ONTO.isbn, Literal(entity['isbn'])))\n",
    "\n",
    "            if 'description' in entity:\n",
    "                self.graph.add((entity_uri, self.ONTO.description, Literal(entity['description'])))\n",
    "\n",
    "            if 'maturityRating' in entity:\n",
    "                self.graph.add((entity_uri, self.ONTO.maturityRating, Literal(entity['maturityRating'])))\n",
    "\n",
    "            if 'epubAccessibility' in entity:\n",
    "                self.graph.add((entity_uri, self.ONTO.epubAccesibility, Literal(entity['epubAccessibility'])))\n",
    "\n",
    "            #Meto cada autor como una instancia con su uri y label y lo relaciono con el libro \n",
    "            if 'autores' in entity:\n",
    "                for autor in entity['autores']:\n",
    "                    self.graph.add((autor[0], RDF.type, self.ONTO[\"Autor\"]))\n",
    "                    self.graph.add((autor[0], RDFS.label, Literal((autor[1]))))\n",
    "                    self.graph.add((entity_uri, self.ONTO.tieneAutor, autor[0]))\n",
    "\n",
    "            #Meto cada editorial como una instancia con su uri y label y lo relaciono con el libro \n",
    "            if 'editorial' in entity:\n",
    "                self.graph.add((entity['editorial'][0], RDF.type, self.ONTO[\"Editorial\"]))\n",
    "                self.graph.add((entity['editorial'][0], RDFS.label, Literal(entity['editorial'][1])))\n",
    "                self.graph.add((entity_uri, self.ONTO.tieneEditorial, entity['editorial'][0]))\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05266ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando 1238 resultados...\n",
      "Procesamiento completado\n"
     ]
    }
   ],
   "source": [
    "book_onto = BookGenreOntology()\n",
    "rdf_graph = book_onto.build_genre_taxonomy_from_wikidata(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01d491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_onto.add_instances_to_ontology(50) #Añadir hasta 50 libros por género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2c0b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontología guardada en: data\\grafo_save.html\n"
     ]
    }
   ],
   "source": [
    "sbc.save(book_onto.graph, \"grafo_save.html\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "806e4956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontología guardada en: data\\grafo_save_ttl.ttl\n"
     ]
    }
   ],
   "source": [
    "sbc.save(book_onto.graph, \"grafo_save_ttl.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4bb55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/grafo_recomendador.html\n"
     ]
    }
   ],
   "source": [
    "sbc.show_graph(rdf_graph, \"grafo_save.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1ecea8",
   "metadata": {},
   "source": [
    "# Similitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e3a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cargamos el grafo\n",
    "graph = sbc.load(\"grafo_save.html\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577e5fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/grafo_save.html\n"
     ]
    }
   ],
   "source": [
    "sbc.show_graph(graph, \"grafo_save.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71adea0d",
   "metadata": {},
   "source": [
    "## Recomendacion dado un libro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5951311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import deque\n",
    "\n",
    "#Funcion para calcular la distancia entre dos libros. Retorna la distancia y el camino\n",
    "def find_path_and_distance(graph, book1_uri, book2_uri, max_depth=10):\n",
    "\n",
    "    if book1_uri == book2_uri:\n",
    "        return 0, [book1_uri]\n",
    "    \n",
    "    adj_graph = {}\n",
    "    def add_edge(u, v):\n",
    "        adj_graph.setdefault(u, set()).add(v)\n",
    "        adj_graph.setdefault(v, set()).add(u)\n",
    "\n",
    "    for s, p, o in graph.triples((None, ONTO.tieneGenero, None)):\n",
    "        if isinstance(s, URIRef) and isinstance(o, URIRef): add_edge(s, o)\n",
    "        \n",
    "    for s, p, o in graph.triples((None, RDFS.subClassOf, None)):\n",
    "        if isinstance(s, URIRef) and isinstance(o, URIRef): add_edge(s, o)\n",
    "\n",
    "    # El BFS ahora guarda el camino: (nodo_actual, distancia, camino_recorrido)\n",
    "    visited = {book1_uri}\n",
    "    queue = deque([(book1_uri, 0, [book1_uri])])\n",
    "\n",
    "    while queue:\n",
    "        current, distance, path = queue.popleft()\n",
    "        if distance >= max_depth: continue\n",
    "\n",
    "        for neighbor in adj_graph.get(current, set()):\n",
    "            if neighbor == book2_uri:\n",
    "                return distance + 1, path + [neighbor]\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                queue.append((neighbor, distance + 1, path + [neighbor]))\n",
    "    \n",
    "    return -1, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f48576d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,\n",
       " [rdflib.term.URIRef('http://librosxxi.org/book/_titulo=amanecer'),\n",
       "  rdflib.term.URIRef('http://www.wikidata.org/entity/Q11820949'),\n",
       "  rdflib.term.URIRef('http://www.wikidata.org/entity/Q474090'),\n",
       "  rdflib.term.URIRef('http://www.wikidata.org/entity/Q948970'),\n",
       "  rdflib.term.URIRef('http://www.wikidata.org/entity/Q8261'),\n",
       "  rdflib.term.URIRef('http://www.wikidata.org/entity/Q3056541'),\n",
       "  rdflib.term.URIRef('http://www.wikidata.org/entity/Q4914883'),\n",
       "  rdflib.term.URIRef('http://librosxxi.org/book/_titulo=a_man')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Codigo de prueba de la función de distancia\n",
    "book1_uri = URIRef(\"http://librosxxi.org/book/_titulo=amanecer\")\n",
    "book2_uri = URIRef(\"http://librosxxi.org/book/_titulo=a_man\")\n",
    "find_path_and_distance(graph, book1_uri, book2_uri, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#Función de recomendación de libros con pesos\n",
    "def recommend_weighted_books(graph, target_book_uri, top_n=5, randomness=0.1):\n",
    "  \n",
    "    #pesos \n",
    "    WEIGHT_AUTHOR = 0.5    # Mucha importancia si es el mismo autor\n",
    "    WEIGHT_PUBLISHER = 0.2 # Importancia media si es la misma editorial\n",
    "    # La similitud de género (distancia) será la base (máximo 1.0)\n",
    "    \n",
    "    all_books = set()\n",
    "    for s, p, o in graph.triples((None, RDF.type, ONTO[\"LibrosXXI\"])):\n",
    "        if s != target_book_uri:\n",
    "            all_books.add(s)\n",
    "            \n",
    "    # Extraer metadatos del libro objetivo para comparar\n",
    "    target_authors = set(graph.objects(target_book_uri, ONTO.tieneAutor))\n",
    "    target_pub = graph.value(target_book_uri, ONTO.tieneEditorial)\n",
    "\n",
    "    candidates = []\n",
    "    for book_uri in all_books:\n",
    "        #Similitud de genero\n",
    "        dist, path = find_path_and_distance(graph, target_book_uri, book_uri)\n",
    "        if dist == -1: continue # Si no hay conexión alguna, ignorar\n",
    "        \n",
    "        genre_sim = 1 / (dist + 1)\n",
    "        \n",
    "        #Bonus por autor comun, tengo en cuenta que puede haber varios autores\n",
    "        author_bonus = 0\n",
    "        current_authors = set(graph.objects(book_uri, ONTO.tieneAutor))\n",
    "        if target_authors.intersection(current_authors):\n",
    "            author_bonus = WEIGHT_AUTHOR\n",
    "            \n",
    "        #Bonus por editorial comun\n",
    "        pub_bonus = 0\n",
    "        current_pub = graph.value(book_uri, ONTO.tieneEditorial)\n",
    "        if target_pub and current_pub and target_pub == current_pub:\n",
    "            pub_bonus = WEIGHT_PUBLISHER\n",
    "            \n",
    "        #agregamos un bonus de aleatoriedad para tener algo de serendipia\n",
    "        luck = random.uniform(0, randomness)\n",
    "        final_score = genre_sim + author_bonus + pub_bonus + luck\n",
    "        \n",
    "        label = graph.value(book_uri, RDFS.label) or str(book_uri).split('=')[-1]\n",
    "        candidates.append({\n",
    "            'label': label,\n",
    "            'score': round(final_score, 3),\n",
    "            'reasons': {\n",
    "                'same_author': author_bonus > 0,\n",
    "                'same_pub': pub_bonus > 0,\n",
    "                'genre_dist': dist, \n",
    "                'path': path\n",
    "            }\n",
    "        })\n",
    "\n",
    "    #ordenados por score y devolvemos los top \n",
    "    candidates.sort(key=lambda x: x['score'], reverse=True)\n",
    "    return candidates[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "497b9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Procesa una recomendacion de ejemplo y la devuelve en texto comprensible\n",
    "def explain_recommendations(graph, target_book_uri, recommendations):\n",
    "    target_label = graph.value(target_book_uri, RDFS.label) or \"Libro seleccionado\"\n",
    "    print(f\"\\n--- Explicación para: {target_label} ---\")\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        print(f\"\\nRECOMENDACIÓN: {rec['label']} (Score: {rec['score']})\")\n",
    "        \n",
    "        # Explicar Género y Camino\n",
    "        path = rec['reasons']['path']\n",
    "        dist = rec['reasons']['genre_dist']\n",
    "        \n",
    "        # Traducir URIs a etiquetas para el camino\n",
    "        labels_path = []\n",
    "        for uri in path:\n",
    "            l = graph.value(uri, RDFS.label)\n",
    "            labels_path.append(str(l) if l else str(uri).split('/')[-1])\n",
    "        \n",
    "        print(f\"  • Género: Distancia {dist}. Camino semántico: {' -> '.join(labels_path)}\")\n",
    "        \n",
    "        # Explicar Bonus\n",
    "        if rec['reasons']['same_author']:\n",
    "            print(f\"  • Bonus Autor: Coincidencia de autor detectada (+0.5)\")\n",
    "        if rec['reasons']['same_pub']:\n",
    "            print(f\"  • Bonus Editorial: Ambos publicados por la misma editorial (+0.2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f170f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Explicación para: Amanecer ---\n",
      "\n",
      "RECOMENDACIÓN: Divine Comedy (Score: 0.348)\n",
      "  • Género: Distancia 3. Camino semántico: Amanecer -> philosophical poem -> narrative poetry -> Divine Comedy\n",
      "\n",
      "RECOMENDACIÓN: Máj (Score: 0.341)\n",
      "  • Género: Distancia 3. Camino semántico: Amanecer -> philosophical poem -> narrative poetry -> Máj\n",
      "\n",
      "RECOMENDACIÓN: Willobie His Avisa (Score: 0.338)\n",
      "  • Género: Distancia 3. Camino semántico: Amanecer -> philosophical poem -> narrative poetry -> Willobie His Avisa\n",
      "\n",
      "RECOMENDACIÓN: Childe Harold's Pilgrimage (Score: 0.336)\n",
      "  • Género: Distancia 3. Camino semántico: Amanecer -> philosophical poem -> narrative poetry -> Childe Harold's Pilgrimage\n",
      "\n",
      "RECOMENDACIÓN: Poltava (poem) (Score: 0.329)\n",
      "  • Género: Distancia 3. Camino semántico: Amanecer -> philosophical poem -> narrative poetry -> Poltava (poem)\n"
     ]
    }
   ],
   "source": [
    "libro_ejemplo = URIRef(\"http://librosxxi.org/book/_titulo=amanecer\")\n",
    "recomendacion = recommend_weighted_books(graph, libro_ejemplo, top_n=5)\n",
    "explain_recommendations(graph, libro_ejemplo, recomendacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818e8849",
   "metadata": {},
   "source": [
    "## Agregamos usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "292419c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Función para agregar usuarios al grafo\n",
    "def agregar_usuarios(graph, usuario):\n",
    "        usuario_uri = URIRef(f\"{URL_PROPIA}_usuario={usuario['nombre']}\")\n",
    "        graph.add((usuario_uri, RDF.type, ONTO.Usuario))\n",
    "        graph.add((usuario_uri, RDFS.label, Literal(usuario['nombre'])))\n",
    "        graph.add((usuario_uri, ONTO.edad, Literal(usuario['edad'])))\n",
    "\n",
    "        for libro_uri in usuario['libros_gustados']:\n",
    "            graph.add((usuario_uri, ONTO.leGusta, libro_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d898646",
   "metadata": {},
   "source": [
    "## Generamos 10 usuarios para hacer pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eac24343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from rdflib import URIRef\n",
    "\n",
    "#Listado de libros disponibles\n",
    "libros_disponibles = [\n",
    "    \"12 Days (book)\",\n",
    "    \"20 Hrs. 40 Min.\",\n",
    "    \"25 Images of a Man's Passion\",\n",
    "    \"365 Read-Aloud Bedtime Bible Stories\",\n",
    "    \"44 Scotland Street\",\n",
    "    \"62: A Model Kit\",\n",
    "    \"69 (novel)\",\n",
    "    \"99 Fables\",\n",
    "    \"A Bell for Adano (novel)\",\n",
    "    \"A boccaperta\",\n",
    "    \"A Bridegroom at Fourteen\",\n",
    "    \"A Buyer's Market\",\n",
    "    \"A Cat Abroad\",\n",
    "    \"A Charge to Keep\",\n",
    "    \"A Choice of Magic\",\n",
    "    \"A Closed Book (novel)\",\n",
    "    \"A Confederacy of Dunces\",\n",
    "    \"A Daughter's a Daughter\",\n",
    "    \"A Demon in My View\",\n",
    "    \"A Dog of Flanders\",\n",
    "    \"A Face Like Glass\",\n",
    "    \"A First-Class Story; or, The Perils of Travelling Alone\",\n",
    "    \"A Flight of Pigeons\",\n",
    "    \"A Fortunate Life\",\n",
    "    \"A Friend of the Family (novel)\",\n",
    "    \"A Girl Is a Half-formed Thing\",\n",
    "    \"A God Strolling in the Cool of the Evening\",\n",
    "    \"A Good Clean Fight\",\n",
    "    \"A Hope in the Unseen\",\n",
    "    \"A Journey Around My Room\",\n",
    "    \"A Journey to Lhasa and Central Tibet\",\n",
    "    \"A Journey to the Rivers\",\n",
    "    \"A Lady's Life in the Rocky Mountains\",\n",
    "    \"A Life of Contrasts\",\n",
    "    \"A Lineage of Grace\",\n",
    "    \"A Lion's Tale\",\n",
    "    \"A London Life\",\n",
    "    \"A Man\",\n",
    "    \"A Man Was Going Down the Road\",\n",
    "    \"A Narrative of the Captivity and Restoration of Mrs. Mary Rowlandson\",\n",
    "    \"A Novel about a Good Person\",\n",
    "    \"A Passionate Pilgrim\",\n",
    "    \"A Peep Behind the Scenes (novel)\",\n",
    "    \"A Riddle of Roses\",\n",
    "    \"A Rose Beyond the Thames\",\n",
    "    \"A Sentimental Journey Through France and Italy\",\n",
    "    \"A Separate Reality\",\n",
    "    \"A Short History of the Confederate States of America\",\n",
    "    \"A Son of the Soil\",\n",
    "    \"A Stranger to Myself: The Inhumanity of War: Russia, 1941–1944\",\n",
    "    \"A Tale of a Tub\",\n",
    "    \"A Thousand Tomorrows\",\n",
    "    \"A Tourist in Africa\",\n",
    "    \"A Tramp Abroad\",\n",
    "    \"A Traveller in Time\",\n",
    "    \"A Watcher in the Woods\",\n",
    "    \"A White House Diary\",\n",
    "    \"A Wizard of Earthsea\",\n",
    "    \"A Woman's Burden\",\n",
    "    \"A World for Julius (novel)\",\n",
    "    \"A World with No Shore\",\n",
    "    \"Abel\",\n",
    "    \"Abeng (novel)\",\n",
    "    \"Absent in the Spring\",\n",
    "    \"Accelerando\",\n",
    "    \"Acoso textual\",\n",
    "    \"Acts of God (novel)\",\n",
    "    \"A.D.: New Orleans After the Deluge\",\n",
    "    \"Adrista\",\n",
    "    \"Adventures of Wim\",\n",
    "    \"Aesop's Fables (Pinkney book)\",\n",
    "    \"Aetnaeae\",\n",
    "    \"After the Plague\",\n",
    "    \"Agatha Christie's Secret Notebooks\",\n",
    "    \"Aki-wayn-zih\",\n",
    "    \"Alaung Mintayagyi Ayedawbon\",\n",
    "    \"Alaungpaya Ayedawbon\",\n",
    "    \"Albidaro and the Mischievous Dream\",\n",
    "    \"Alfred Hitchcock's Anthology – Volume 5\",\n",
    "    \"Alice, I Think (novel)\",\n",
    "    \"Alice in Sunderland\",\n",
    "    \"Aline and Valcour\",\n",
    "    \"All Families Are Psychotic\",\n",
    "    \"All God's Children Need Traveling Shoes\",\n",
    "    \"All Heads Turn When the Hunt Goes by\",\n",
    "    \"All in a Lifetime\",\n",
    "    \"All Quiet on the Orient Express\",\n",
    "    \"All Quiet on the Western Front\",\n",
    "    \"All the World's Mornings\",\n",
    "    \"Alzheimer's Story\",\n",
    "    \"Amanecer\",\n",
    "    \"Amazon Adventure\",\n",
    "    \"Amelia Rules!\",\n",
    "    \"American Born Chinese (graphic novel)\",\n",
    "    \"American Menu\",\n",
    "    \"Among the Believers\",\n",
    "    \"Among the Betrayed\",\n",
    "    \"Amuktamalyada\",\n",
    "    \"An American Demon\",\n",
    "    \"An American Tragedy\",\n",
    "    \"An Area of Darkness\",\n",
    "    \"An Awfully Big Adventure (novel)\",\n",
    "    \"An Ice-Cream War\",\n",
    "    \"Anatomy of a Disappearance\",\n",
    "    \"Anchu (novel)\",\n",
    "    \"Anecdotes of Oyasama\",\n",
    "    \"Angelus ad aras\",\n",
    "    \"Angus, Thongs and Full-Frontal Snogging\",\n",
    "    \"Angéline de Montbrun\",\n",
    "    \"Anon Pls.\",\n",
    "    \"Anzukko\",\n",
    "    \"Apache\",\n",
    "    \"Aplec de Rondalles Mallorquines d'en Jordi des Racó\",\n",
    "    \"Apollonius of Tyre\"\n",
    "]\n",
    "\n",
    "#creamos las uris de los libros\n",
    "libros_uris = {titulo: URIRef(f\"{URL_PROPIA}_titulo={titulo.replace(' ', '_').replace(':', '').replace(',', '').replace('(', '').replace(')', '').replace('.', '').lower()}\") \n",
    "               for titulo in libros_disponibles}\n",
    "\n",
    "##Seleccionamos un par de libros para que coincidan y los usuarios de prueba tengan similitudes\n",
    "libros_populares = [\n",
    "    \"A Confederacy of Dunces\",\n",
    "    \"All Quiet on the Western Front\",\n",
    "    \"A Wizard of Earthsea\",\n",
    "    \"Accelerando\",\n",
    "    \"An American Tragedy\",\n",
    "    \"Aesop's Fables (Pinkney book)\",\n",
    "    \"Alice in Sunderland\",\n",
    "    \"American Born Chinese (graphic novel)\",\n",
    "    \"After the Plague\",\n",
    "    \"All Families Are Psychotic\"\n",
    "]\n",
    "\n",
    "#generamos 10 usuarioos\n",
    "usuarios = []\n",
    "nombres = ['juan_perez', 'maria_garcia', 'carlos_lopez', 'ana_martinez', 'luis_rodriguez',\n",
    "           'laura_hernandez', 'pedro_gonzalez', 'sofia_diaz', 'miguel_sanchez', 'elena_ruiz']\n",
    "\n",
    "for i in range(10):\n",
    "    #cada usuario tendrá 10 libros gustados\n",
    "    #mezcla de libros populares (30-50%) y libros aleatorios\n",
    "    num_populares = random.randint(3, 5)\n",
    "    seleccion_populares = random.sample(libros_populares, num_populares)\n",
    "    \n",
    "    #completar con libros aleatorios\n",
    "    libros_restantes = [libro for libro in libros_disponibles if libro not in seleccion_populares]\n",
    "    seleccion_aleatoria = random.sample(libros_restantes, 10 - num_populares)\n",
    "    \n",
    "    libros_usuario = seleccion_populares + seleccion_aleatoria\n",
    "    \n",
    "    #crear lista de uris\n",
    "    libros_uris_usuario = [libros_uris[libro] for libro in libros_usuario]\n",
    "    \n",
    "    usuario = {\n",
    "        'nombre': nombres[i],\n",
    "        'edad': random.randint(20, 65),\n",
    "        'libros_gustados': libros_uris_usuario\n",
    "    }\n",
    "    \n",
    "    usuarios.append(usuario)\n",
    "\n",
    "for usuario in usuarios:\n",
    "    agregar_usuarios(graph, usuario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7484f43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontología guardada en: data\\grafo_con_usuarios.ttl\n"
     ]
    }
   ],
   "source": [
    "sbc.save(graph, \"grafo_con_usuarios.ttl\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50d002bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontología guardada en: data\\grafo_con_usuarios.html\n"
     ]
    }
   ],
   "source": [
    "sbc.save(graph, \"grafo_con_usuarios.html\", format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0753f507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://librosxxi.org/book/_usuario=maria_garcia comparte libros: {rdflib.term.URIRef('http://librosxxi.org/book/_titulo=a_wizard_of_earthsea'), rdflib.term.URIRef('http://librosxxi.org/book/_titulo=american_born_chinese_graphic_novel')}\n",
      "http://librosxxi.org/book/_usuario=luis_rodriguez comparte libros: {rdflib.term.URIRef('http://librosxxi.org/book/_titulo=all_quiet_on_the_western_front'), rdflib.term.URIRef('http://librosxxi.org/book/_titulo=a_wizard_of_earthsea'), rdflib.term.URIRef('http://librosxxi.org/book/_titulo=365_read-aloud_bedtime_bible_stories')}\n",
      "http://librosxxi.org/book/_usuario=laura_hernandez comparte libros: {rdflib.term.URIRef('http://librosxxi.org/book/_titulo=a_confederacy_of_dunces'), rdflib.term.URIRef(\"http://librosxxi.org/book/_titulo=a_buyer's_market\"), rdflib.term.URIRef('http://librosxxi.org/book/_titulo=all_quiet_on_the_western_front'), rdflib.term.URIRef('http://librosxxi.org/book/_titulo=a_wizard_of_earthsea'), rdflib.term.URIRef(\"http://librosxxi.org/book/_titulo=aesop's_fables_pinkney_book\")}\n",
      "http://librosxxi.org/book/_usuario=pedro_gonzalez comparte libros: {rdflib.term.URIRef('http://librosxxi.org/book/_titulo=all_quiet_on_the_western_front'), rdflib.term.URIRef('http://librosxxi.org/book/_titulo=a_wizard_of_earthsea'), rdflib.term.URIRef(\"http://librosxxi.org/book/_titulo=aesop's_fables_pinkney_book\")}\n",
      "http://librosxxi.org/book/_usuario=carlos_lopez comparte libros: {rdflib.term.URIRef('http://librosxxi.org/book/_titulo=all_quiet_on_the_western_front'), rdflib.term.URIRef('http://librosxxi.org/book/_titulo=a_confederacy_of_dunces')}\n",
      "http://librosxxi.org/book/_usuario=sofia_diaz comparte libros: {rdflib.term.URIRef('http://librosxxi.org/book/_titulo=all_quiet_on_the_western_front'), rdflib.term.URIRef(\"http://librosxxi.org/book/_titulo=aesop's_fables_pinkney_book\"), rdflib.term.URIRef('http://librosxxi.org/book/_titulo=american_born_chinese_graphic_novel')}\n",
      "http://librosxxi.org/book/_usuario=miguel_sanchez comparte libros: {rdflib.term.URIRef('http://librosxxi.org/book/_titulo=all_quiet_on_the_western_front')}\n",
      "http://librosxxi.org/book/_usuario=elena_ruiz comparte libros: {rdflib.term.URIRef('http://librosxxi.org/book/_titulo=all_quiet_on_the_western_front')}\n",
      "http://librosxxi.org/book/_usuario=ana_martinez comparte libros: {rdflib.term.URIRef('http://librosxxi.org/book/_titulo=a_watcher_in_the_woods')}\n"
     ]
    }
   ],
   "source": [
    "from rdflib import Namespace\n",
    "\n",
    "ONTO = Namespace(\"http://librosxxi.org/book-ontology/\")\n",
    "\n",
    "usuario_x = URIRef(\"http://librosxxi.org/book/_usuario=juan_perez\")\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT DISTINCT ?otroUsuario ?libro\n",
    "WHERE {{\n",
    "  <{usuario_x}> onto:leGusta ?libro .\n",
    "  ?otroUsuario onto:leGusta ?libro .\n",
    "  FILTER (?otroUsuario != <{usuario_x}>)\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "usuarios_similares = {}\n",
    "\n",
    "for row in graph.query(query, initNs={\"onto\": ONTO}):\n",
    "    otro = row.otroUsuario\n",
    "    libro = row.libro\n",
    "    usuarios_similares.setdefault(otro, set()).add(libro)\n",
    "\n",
    "for u, libros in usuarios_similares.items():\n",
    "    print(u, \"comparte libros:\", libros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b13ee6",
   "metadata": {},
   "source": [
    "## Función de Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0f22472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para calcular la similitud de Jaccard entre dos usuarios\n",
    "def jaccard_users(graph, user1_uri, user2_uri):\n",
    "    \"\"\"\n",
    "    Calcula la similitud de Jaccard entre dos usuarios\n",
    "    \"\"\"\n",
    "    libros_u1 = set(graph.objects(user1_uri, ONTO.leGusta))\n",
    "    libros_u2 = set(graph.objects(user2_uri, ONTO.leGusta))\n",
    "    \n",
    "    if not libros_u1 and not libros_u2:\n",
    "        return 0.0\n",
    "    \n",
    "    interseccion = libros_u1.intersection(libros_u2)\n",
    "    union = libros_u1.union(libros_u2)\n",
    "    \n",
    "    return round(len(interseccion) / len(union), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0049e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juan_perez ↔ laura_hernandez → Jaccard = 0.333\n",
      "{rdflib.term.URIRef('http://librosxxi.org/book/_titulo=99_fables'): 0.333, rdflib.term.URIRef('http://librosxxi.org/book/_titulo=abeng_novel'): 0.333, rdflib.term.URIRef('http://librosxxi.org/book/_titulo=among_the_believers'): 0.333, rdflib.term.URIRef('http://librosxxi.org/book/_titulo=anon_pls'): 0.333, rdflib.term.URIRef('http://librosxxi.org/book/_titulo=a_london_life'): 0.333}\n"
     ]
    }
   ],
   "source": [
    "#Umbral de similitud para considerar usuarios similares\n",
    "UMBRAL_JACCARD = 0.3\n",
    "usuarios = set(graph.subjects(RDF.type, ONTO.Usuario))\n",
    "jaccard_results = []\n",
    "\n",
    "for user in usuarios:\n",
    "    if user == usuario_x:\n",
    "        continue  # Omitir el usuario de referencia\n",
    "    sim = jaccard_users(graph, usuario_x, user)\n",
    "    if sim > UMBRAL_JACCARD: \n",
    "        jaccard_results.append((usuario_x, user, sim))\n",
    "\n",
    "libros_usuario = {}\n",
    "libros_originales = set(graph.objects(usuario_x, ONTO.leGusta))\n",
    "\n",
    "for u1, u2, sim in sorted(jaccard_results, key=lambda x: x[2], reverse=True):\n",
    "    label_u1 = graph.value(u1, RDFS.label)\n",
    "    label_u2 = graph.value(u2, RDFS.label)\n",
    "    libros_usuario2= set(graph.objects(u2, ONTO.leGusta))\n",
    "\n",
    "    for libro in libros_usuario2:\n",
    "        if libro not in libros_originales:\n",
    "            if libro in libros_usuario:\n",
    "                libros_usuario[libro] += sim\n",
    "            else:\n",
    "                libros_usuario[libro] = sim\n",
    "     \n",
    "    print(f\"{label_u1} ↔ {label_u2} → Jaccard = {sim}\")\n",
    "\n",
    "print(libros_usuario)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
